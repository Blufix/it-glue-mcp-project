#!/usr/bin/env python3
"""
Full sync pipeline for IT Glue data with rate limiting.
Populates PostgreSQL, generates embeddings for Qdrant, and creates graph in Neo4j.
"""

import asyncio
import sys
from pathlib import Path
import logging
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent))

from src.sync.itglue_sync import ITGlueSyncManager
from src.config.settings import settings

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def run_full_sync(test_mode: bool = False):
    """
    Run full sync pipeline with IT Glue API rate limiting.
    
    Args:
        test_mode: If True, only sync a small subset for testing
    """
    print("=" * 80)
    print("IT GLUE FULL SYNC PIPELINE")
    print("=" * 80)
    print(f"""
Configuration:
  API URL:        {settings.itglue_api_url}
  Rate Limit:     {settings.itglue_rate_limit} requests/minute
  Sync Mode:      {'TEST (limited data)' if test_mode else 'FULL'}
  
Databases:
  PostgreSQL:     {settings.database_url.split('@')[1] if '@' in settings.database_url else 'configured'}
  Qdrant:         {settings.qdrant_url}
  Neo4j:          bolt://localhost:7688
  
Process:
  1. Sync from IT Glue API (with rate limiting)
  2. Generate embeddings (Ollama/nomic)  
  3. Update graph relationships (Neo4j)
""")
    print("=" * 80)
    
    start_time = datetime.now()
    
    # Initialize sync manager
    sync_manager = ITGlueSyncManager()
    
    try:
        if test_mode:
            # In test mode, only sync specific organization(s)
            print("\nüß™ TEST MODE: Syncing limited data...")
            print("   Using Faucets organization as test subject")
            
            # You can specify organization IDs here
            # For now, let's sync the Faucets org we've been using
            test_org_ids = ["3208599755514479"]  # Faucets org ID
            
            await sync_manager.sync_all(organization_ids=test_org_ids)
        else:
            # Full sync - all organizations
            print("\nüöÄ FULL SYNC: This may take a while...")
            print("   Rate limiting will ensure API compliance")
            
            await sync_manager.sync_all()
        
        # After sync, generate embeddings and update graph
        print("\n" + "=" * 60)
        print("POST-SYNC PROCESSING")
        print("=" * 60)
        
        # 1. Generate embeddings for new entities
        print("\nü§ñ Generating embeddings for new entities...")
        # For now, we'll skip auto-generation since it needs the function to be added
        print("   [Skipped - run generate_embeddings_nomic.py separately]")
        
        # 2. Update Neo4j graph
        print("\nüîó Updating Neo4j graph relationships...")
        # For now, we'll skip auto-update since it needs imports
        print("   [Skipped - run populate_neo4j_graph.py separately]")
        
        # 3. Verify integration
        print("\n‚úÖ Verifying integration...")
        # We can check basic stats instead
        from src.data import db_manager
        await db_manager.initialize()
        async with db_manager.get_session() as session:
            from sqlalchemy import text
            result = await session.execute(text("""
                SELECT entity_type, COUNT(*) as count
                FROM itglue_entities
                GROUP BY entity_type
                ORDER BY count DESC
            """))
            print("\n   Entity counts by type:")
            for row in result:
                print(f"     {row.entity_type}: {row.count}")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Sync interrupted by user")
    except Exception as e:
        logger.error(f"Sync failed: {e}", exc_info=True)
        print(f"\n‚ùå Sync failed: {e}")
        return False
    
    # Calculate and display timing
    end_time = datetime.now()
    duration = end_time - start_time
    
    print("\n" + "=" * 80)
    print("SYNC COMPLETE")
    print("=" * 80)
    print(f"""
‚è±Ô∏è Duration: {duration}
üìä Stats: Check summary above

Next steps:
  1. Test unified search: python test_unified_search.py
  2. Check integration: python check_full_integration.py
  3. Use MCP server with enhanced search capabilities
""")
    print("=" * 80)
    
    return True


async def main():
    """Main entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Sync IT Glue data with rate limiting')
    parser.add_argument(
        '--test',
        action='store_true',
        help='Run in test mode (limited data)'
    )
    parser.add_argument(
        '--org-id',
        type=str,
        help='Sync specific organization ID only'
    )
    
    args = parser.parse_args()
    
    if args.org_id:
        # Sync specific organization
        print(f"Syncing organization {args.org_id}...")
        from src.sync.itglue_sync import sync_single_organization
        await sync_single_organization(args.org_id)
    else:
        # Run full or test sync
        await run_full_sync(test_mode=args.test)


if __name__ == "__main__":
    asyncio.run(main())